{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping StreetEasy.com to analyze housing price in New York City "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My goal here is to collect housing prices for both rental and sale in New York city. I looked at three major real estate website including Trulia, Zillow, and StreetEasy. Comparing to the other two websites, StreetEasy gives the most information on the searching results page and the format of each listing is very consistent, which is great for the purpose of web-scraping.<br\\ >\n",
    "<a href=\"http://streeteasy.com/\">\n",
    "<img \"StreetEasy\" src=\"map/streetEasy_logo.jpg\" height=\"30px\" width=\"150px\"/></a><br\\ >\n",
    "\n",
    "Web scraping is done using the beautifulsoup package in Python. I created two functions that can loop through all the pages of searching results, and also empty strings to store results. Below are the steps I took to scrape StreetEasy:\n",
    "1. Analyzing the HTML page: HTML code of a web page can be viewed by right click and selecting 'Inspect'. This helps us identifying the HTML tags of the information to be scraped\n",
    "2. Making the soup!: It is important to select the correct parser for your data type. I used HTML parser.\n",
    "3. Navigating the parse tree and iterate through tags: once the soup is made, we have the HTML code in Python. We can then find our desired information by searching through HTML tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 24\u001b[0m\n\u001b[1;32m     22\u001b[0m p \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m20\u001b[39m))\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m p:\n\u001b[0;32m---> 24\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[43msoup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfindAll\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mul\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mclass\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlist-card-details\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mcontents) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m     25\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     26\u001b[0m             price\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mfloat\u001b[39m(soup\u001b[38;5;241m.\u001b[39mfindAll(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiv\u001b[39m\u001b[38;5;124m'\u001b[39m, {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlist-card-price\u001b[39m\u001b[38;5;124m'\u001b[39m})[x]\u001b[38;5;241m.\u001b[39mcontents[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m$\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Create an empty list to store data\n",
    "data = []\n",
    "\n",
    "\n",
    "#path = \"Pretty_Resources/Zillow/Zillow Rentals\"\n",
    "\n",
    "#for file in os.listdir(path):\n",
    "#    if file.endswith(\".html\"):\n",
    " #       file_path = os.path.join(path, file)  # Construct the full file path\n",
    "file_path=\"Pretty_Resources/Zillow/Zillow Rentals/pretty_page_2.html\"\n",
    "with open(file_path) as f:\n",
    "    soup = BeautifulSoup(f, 'html.parser')\n",
    "    x = 0\n",
    "    bedrooms = []\n",
    "    bathrooms = []\n",
    "    sqft = []\n",
    "    price = []\n",
    "    p = list(range(20))\n",
    "    for v in p:\n",
    "        if len(soup.findAll('ul', {'class' : 'list-card-details'})[x].contents) == 3:\n",
    "            try:\n",
    "                price.append(float(soup.findAll('div', {'class' : 'list-card-price'})[x].contents[0].replace('$', '').replace(',', '')))\n",
    "                bedrooms.append(float(soup.findAll('ul', {'class' : 'list-card-details'})[x].contents[0].contents[0]))\n",
    "                bathrooms.append(float(soup.findAll('ul', {'class' : 'list-card-details'})[x].contents[1].contents[0]))\n",
    "                sqft.append(float(soup.findAll('ul', {'class' : 'list-card-details'})[x].contents[2].contents[0].replace(',', '')))\n",
    "                x = x + 1\n",
    "            except:\n",
    "                if len(price) > len(bedrooms):\n",
    "                    bedrooms.append(None)\n",
    "                    bathrooms.append(float(soup.findAll('ul', {'class' : 'list-card-details'})[x].contents[1].contents[0]))\n",
    "                    sqft.append(float(soup.findAll('ul', {'class' : 'list-card-details'})[x].contents[2].contents[0].replace(',', '')))\n",
    "                    x = x + 1\n",
    "                elif len(bedrooms) > len(bathrooms):\n",
    "                    bathrooms.append(None)\n",
    "                    sqft.append(float(soup.findAll('ul', {'class' : 'list-card-details'})[x].contents[2].contents[0].replace(',', '')))\n",
    "                    x = x + 1\n",
    "                else:\n",
    "                    sqft.append(None)\n",
    "                    x = x + 1\n",
    "                continue\n",
    "        else:\n",
    "            x = x + 1\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "for file in os.listdir(path):\n",
    "    if file.endswith(\".html\"):\n",
    "        file_path = os.path.join(path, file)  # Construct the full file path\n",
    "        with open(file_path) as f:\n",
    "            soup = BeautifulSoup(f, 'html.parser')\n",
    "\n",
    "            # Find all <address> tags with data-test=\"property-card-addr\"\n",
    "            for address_tag in soup.find_all('address', attrs={'data-test': 'property-card-addr'}):\n",
    "                address = address_tag.get_text(strip=True)\n",
    "\n",
    "            for price_tag in soup.find_all('span', class_='PropertyCardWrapper__StyledPriceLine-srp__sc-16e8gqd-1 iMKTKr',\n",
    "                                          attrs={'data-test': 'property-card-price'}):\n",
    "                price = price_tag.get_text(strip=True)\n",
    "\n",
    "            # Find all <a> tags with class=\"StyledPropertyCardDataArea-c11n-8-84-3__sc-yipmu-0\"\n",
    "            # and data-test=\"property-card-link\"\n",
    "            for a_tag in soup.find_all('a', class_='StyledPropertyCardDataArea-c11n-8-84-3__sc-yipmu-0',\n",
    "                                       attrs={'data-test': 'property-card-link'}):\n",
    "                url = a_tag.get('href')\n",
    "                address_inside_a = a_tag.text.strip()\n",
    "\n",
    "            # Find all <ul> tags with class=\"StyledPropertyCardHomeDetailsList-c11n-8-84-3__sc-1xvdaej-0\"\n",
    "            for ul_tag in soup.find_all('ul', class_='StyledPropertyCardHomeDetailsList-c11n-8-84-3__sc-1xvdaej-0'):\n",
    "                # Find all <li> tags within the <ul> tag\n",
    "                home_details = ul_tag.find_all('li')\n",
    "                # Initialize variables to store bedroom, bathroom, and square footage information\n",
    "                bedrooms = []\n",
    "                bathrooms = []\n",
    "                sqft = []\n",
    "                # Extract data from each <li> tag\n",
    "                for li_tag in home_details:\n",
    "                    text = li_tag.get_text(strip=True)\n",
    "                    if 'bd' in text:\n",
    "                        bedrooms = text.replace('bd', '').strip()\n",
    "                    elif 'ba' in text:\n",
    "                        bathrooms = text.replace('ba', '').strip()\n",
    "                    elif 'sqft' in text:\n",
    "                        sqft = text.replace('sqft', '').strip()\n",
    "\n",
    "                    # Append data for each property to the list\n",
    "                    data.append({'File Name': file,'Address': address, 'Price': price, 'Bedrooms': bedrooms,\n",
    "                                 'Bathrooms': bathrooms, 'Square Footage': sqft, 'URL': url})\n",
    "\"\"\"\n",
    "\n",
    "# Create a DataFrame from the list of dictionaries\n",
    "df = pd.DataFrame(data)\n",
    "# Export the DataFrame to a CSV file\n",
    "#csv_file_path = \"property_listings.csv\"\n",
    "#df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "#print(f\"CSV file saved successfully: {csv_file_path}\")\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping Pages:   0%|          | 0/1411 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request failed: 403 Client Error: Forbidden for url: https://streeteasy.com/for-rent/nyc?page=1\n",
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>street</th>\n",
       "      <th>price</th>\n",
       "      <th>where</th>\n",
       "      <th>bed</th>\n",
       "      <th>bath</th>\n",
       "      <th>size</th>\n",
       "      <th>furnished</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [street, price, where, bed, bath, size, furnished]\n",
       "Index: []"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some listings the information on number of bedroom, number of bathroom, and apartment size is incomplete or mixed up. I performed data manipulation to fix the mistaken values and clean up the extra symbols such as comma and dollar sign. <br\\ >\n",
    "Finally, I have two data sets containing the housing information for apartments for rent and apartments for sale. My for sale data set has 8,456 rows and 8 columns, and the for rent data set has 20,988 rows and 7 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'street' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m data\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstreet\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[43mstreet\u001b[49m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprice\u001b[39m\u001b[38;5;124m'\u001b[39m:price,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwhere\u001b[39m\u001b[38;5;124m'\u001b[39m:where,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbed\u001b[39m\u001b[38;5;124m'\u001b[39m:bed, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbath\u001b[39m\u001b[38;5;124m'\u001b[39m:bath, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msize\u001b[39m\u001b[38;5;124m'\u001b[39m:size,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfurnished\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m0\u001b[39m}\n\u001b[1;32m      4\u001b[0m data\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mDataFrame(data)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#is the apartment furnished?\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'street' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
